{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import library\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import os\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn import cluster\n",
    "from sklearn import metrics\n",
    "import TextProcess.text_process as text_process\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_input(file_name):\n",
    "    \"\"\"\n",
    "    read input file which is tsv file\n",
    "    \n",
    "    \"\"\"\n",
    "    df =  pd.read_csv(os.path.join('./data',file_name), sep=\"\\t\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>product_id</th>\n",
       "      <th>description2</th>\n",
       "      <th>title</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>100191</td>\n",
       "      <td>JACK OF CLUBS PSA 5 9 OF SPADES PSA 5 7 OF HEA...</td>\n",
       "      <td>(4) 1889 N220 KINNEY HARLEQUIN PSA 5 EX TOBACC...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>100217</td>\n",
       "      <td>Powered by Frooition About us Newsletter Feedb...</td>\n",
       "      <td>12 Jars Of Dalfour Beauty Gold Seal EXCEL Beau...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>100272</td>\n",
       "      <td>StrawberryNET Check out our eBay store &gt;&gt; Cate...</td>\n",
       "      <td>Perricone MD Vitamin C Ester Eye Serum 15ml/0.5oz</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  product_id                                       description2  \\\n",
       "0           0      100191  JACK OF CLUBS PSA 5 9 OF SPADES PSA 5 7 OF HEA...   \n",
       "1           1      100217  Powered by Frooition About us Newsletter Feedb...   \n",
       "2           2      100272  StrawberryNET Check out our eBay store >> Cate...   \n",
       "\n",
       "                                               title  label  \n",
       "0  (4) 1889 N220 KINNEY HARLEQUIN PSA 5 EX TOBACC...      0  \n",
       "1  12 Jars Of Dalfour Beauty Gold Seal EXCEL Beau...      0  \n",
       "2  Perricone MD Vitamin C Ester Eye Serum 15ml/0.5oz      0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import dataset\n",
    "train=read_input('train.tsv')\n",
    "train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>product_id</th>\n",
       "      <th>description2</th>\n",
       "      <th>title</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>100394</td>\n",
       "      <td>TOP Gold Light 100's 100MM - 1 Box - 200 Tubes...</td>\n",
       "      <td>TOP Gold Light 100's 100MM - 1 Box - 200 Tubes...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>100692</td>\n",
       "      <td>15oceaneshop Add to my favorite sellers Mon. t...</td>\n",
       "      <td>Portable Clear Mini Acrylic Water Pipes Smokin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>100857</td>\n",
       "      <td>StrawberryNET Check out our eBay store &gt;&gt; Cate...</td>\n",
       "      <td>Clarins Daily Energizer Cleansing Gel 75ml/2.5oz</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  product_id                                       description2  \\\n",
       "0           0      100394  TOP Gold Light 100's 100MM - 1 Box - 200 Tubes...   \n",
       "1           1      100692  15oceaneshop Add to my favorite sellers Mon. t...   \n",
       "2           2      100857  StrawberryNET Check out our eBay store >> Cate...   \n",
       "\n",
       "                                               title  label  \n",
       "0  TOP Gold Light 100's 100MM - 1 Box - 200 Tubes...      0  \n",
       "1  Portable Clear Mini Acrylic Water Pipes Smokin...      0  \n",
       "2   Clarins Daily Energizer Cleansing Gel 75ml/2.5oz      0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test=read_input('dev.tsv')\n",
    "test.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(lists):\n",
    "    \"\"\"\n",
    "    Remove noise, normalize and tokenize text\n",
    "    \"\"\"\n",
    "    preprocess_text_list=[]\n",
    "    for i in range(len(lists)):\n",
    "        if lists[i]=='None':\n",
    "            preprocess_text_list.append('None')\n",
    "        else:\n",
    "            try:\n",
    "                preprocess_text_list.append(text_process.text_processing(lists[i]))\n",
    "            except:\n",
    "                preprocess_text_list.append('None')\n",
    "    return (preprocess_text_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenization\n",
    "train_description_tokenize=preprocess_text(train['description2']) #Tokenize description of train set\n",
    "train_title_tokenize=preprocess_text(train['title'])  #Tokenize title of train set\n",
    "test_description_tokenize=preprocess_text(test['description2'])  #Tokenize description of test set\n",
    "test_title_tokenize=preprocess_text(test['title']) #Tokenize title of test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeanEmbeddingVectorizer(object):\n",
    "    def __init__(self, wordtwovec):\n",
    "        self.wordtwovec = wordtwovec\n",
    "        # if a text is empty we should return a vector of zeros\n",
    "        # with the same dimensionality as all the other vectors\n",
    "        self.dim = len(next(iter(wordtwovec.values())))\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return np.array([\n",
    "            np.mean([self.wordtwovec[w] for w in words if w in self.wordtwovec]\n",
    "                    or [np.zeros(self.dim)], axis=0)\n",
    "            for words in X\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Word2Vec_Processing(train_set,test_set,n):\n",
    "    # let X be a list of tokenized texts (i.e. list of lists of tokens)\n",
    "    train_w2v=Word2Vec(train_set, size=n)\n",
    "    test_w2v=Word2Vec(test_set, size=n)\n",
    "    train_w2v_dict = dict(zip(train_w2v.wv.index2word, train_w2v.wv.syn0))\n",
    "    test_w2v_dict = dict(zip(test_w2v.wv.index2word, test_w2v.wv.syn0))\n",
    "    # get vector data\n",
    "    train_vector = MeanEmbeddingVectorizer(train_w2v_dict).transform(train_set)\n",
    "    test_vector=MeanEmbeddingVectorizer(test_w2v_dict).transform(test_set)\n",
    "    return train_vector, test_vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\defaultuser0.LAPTOP-6F0LJR1V\\Anaconda3\\lib\\site-packages\\gensim\\models\\base_any2vec.py:743: UserWarning: C extension not loaded, training will be slow. Install a C compiler and reinstall gensim for fast training.\n",
      "  \"C extension not loaded, training will be slow. \"\n",
      "C:\\Users\\defaultuser0.LAPTOP-6F0LJR1V\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.vectors instead).\n",
      "  \"\"\"\n",
      "C:\\Users\\defaultuser0.LAPTOP-6F0LJR1V\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.vectors instead).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "train_set,test_set=Word2Vec_Processing(train_title_tokenize,test_title_tokenize,200) #Use only title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\defaultuser0.LAPTOP-6F0LJR1V\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.vectors instead).\n",
      "  \"\"\"\n",
      "C:\\Users\\defaultuser0.LAPTOP-6F0LJR1V\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.vectors instead).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "train_set_des,test_set_des=Word2Vec_Processing(train_description_tokenize,test_description_tokenize,200)#Use only description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "my_tags=['Non-violation','Violation']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\defaultuser0.LAPTOP-6F0LJR1V\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.8252063015753939\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "Non-violation       0.83      1.00      0.90      1101\n",
      "    Violation       0.00      0.00      0.00       232\n",
      "\n",
      "    micro avg       0.83      0.83      0.83      1333\n",
      "    macro avg       0.41      0.50      0.45      1333\n",
      " weighted avg       0.68      0.83      0.75      1333\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Train with title\n",
    "logreg = LogisticRegression(n_jobs=1, C=1e5)\n",
    "logreg = logreg.fit(train_set, train['label'])\n",
    "y_pred = logreg.predict(test_set)\n",
    "print('accuracy %s' % accuracy_score(y_pred, test.label))\n",
    "print(classification_report(test.label, y_pred,target_names=my_tags))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results show a good precision and recall on non-violation group. However, precision and recall are extremly bad in case of violation group. It seems like the model only capture a samll amount of actual viola"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\defaultuser0.LAPTOP-6F0LJR1V\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.7959489872468117\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "Non-violation       0.84      0.94      0.88      1101\n",
      "    Violation       0.30      0.13      0.19       232\n",
      "\n",
      "    micro avg       0.80      0.80      0.80      1333\n",
      "    macro avg       0.57      0.53      0.53      1333\n",
      " weighted avg       0.74      0.80      0.76      1333\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Train with description only\n",
    "my_tags=['Non-violation','Violation']\n",
    "logreg = LogisticRegression(n_jobs=1, C=1e5)\n",
    "logreg = logreg.fit(train_set_des, train['label'])\n",
    "y_pred = logreg.predict(test_set_des)\n",
    "print('accuracy %s' % accuracy_score(y_pred, test.label))\n",
    "print(classification_report(test.label, y_pred,target_names=my_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.8259564891222806\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "Non-violation       0.83      1.00      0.90      1101\n",
      "    Violation       0.00      0.00      0.00       232\n",
      "\n",
      "    micro avg       0.83      0.83      0.83      1333\n",
      "    macro avg       0.41      0.50      0.45      1333\n",
      " weighted avg       0.68      0.83      0.75      1333\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\defaultuser0.LAPTOP-6F0LJR1V\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\defaultuser0.LAPTOP-6F0LJR1V\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "#USING OTHER METHOD\n",
    "#Linear Support Vector Machine\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "sgd = SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, random_state=42, max_iter=5, tol=None)\n",
    "sgd.fit(train_set, train['label']) #Use title\n",
    "y_pred = sgd.predict(test_set)\n",
    "\n",
    "print('accuracy %s' % accuracy_score(y_pred, test.label))\n",
    "print(classification_report(test.label, y_pred,target_names=my_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.8042010502625656\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "Non-violation       0.83      0.96      0.89      1101\n",
      "    Violation       0.28      0.08      0.13       232\n",
      "\n",
      "    micro avg       0.80      0.80      0.80      1333\n",
      "    macro avg       0.56      0.52      0.51      1333\n",
      " weighted avg       0.74      0.80      0.76      1333\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\defaultuser0.LAPTOP-6F0LJR1V\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "sgd.fit(train_set_des, train['label']) #Use Description\n",
    "y_pred = sgd.predict(test_set_des)\n",
    "\n",
    "print('accuracy %s' % accuracy_score(y_pred, test.label))\n",
    "print(classification_report(test.label, y_pred,target_names=my_tags))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#USING SMOTE TO DEAL WITH IMBALANCE DATASET\n",
    "#FIT SMOTE\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "train['label'].value_counts()\n",
    "smt = SMOTE()\n",
    "X_train, y_train = smt.fit_sample(train_set_des, train['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\defaultuser0.LAPTOP-6F0LJR1V\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.7749437359339835\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "Non-violation       0.86      0.86      0.86      1101\n",
      "    Violation       0.35      0.35      0.35       232\n",
      "\n",
      "    micro avg       0.77      0.77      0.77      1333\n",
      "    macro avg       0.61      0.61      0.61      1333\n",
      " weighted avg       0.77      0.77      0.77      1333\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#LOGISTIC REGRESSION\n",
    "logreg = logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(test_set_des)\n",
    "print('accuracy %s' % accuracy_score(y_pred, test.label))\n",
    "print(classification_report(test.label, y_pred,target_names=my_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.7719429857464366\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "Non-violation       0.83      0.91      0.87      1101\n",
      "    Violation       0.22      0.12      0.16       232\n",
      "\n",
      "    micro avg       0.77      0.77      0.77      1333\n",
      "    macro avg       0.52      0.51      0.51      1333\n",
      " weighted avg       0.72      0.77      0.74      1333\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\defaultuser0.LAPTOP-6F0LJR1V\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#SUPPORT VECTOR MACHINE\n",
    "sgd.fit(X_train, y_train) #Use Description\n",
    "y_pred = sgd.predict(test_set_des)\n",
    "\n",
    "print('accuracy %s' % accuracy_score(y_pred, test.label))\n",
    "print(classification_report(test.label, y_pred,target_names=my_tags))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#USE NEARMISS TO RESAMPLING\n",
    "from imblearn.under_sampling import NearMiss\n",
    "nr = NearMiss()\n",
    "X_train_nr, y_train_nr = nr.fit_sample(train_set_des, train['label'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\defaultuser0.LAPTOP-6F0LJR1V\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.668417104276069\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "Non-violation       0.86      0.72      0.78      1101\n",
      "    Violation       0.25      0.44      0.31       232\n",
      "\n",
      "    micro avg       0.67      0.67      0.67      1333\n",
      "    macro avg       0.55      0.58      0.55      1333\n",
      " weighted avg       0.75      0.67      0.70      1333\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#LOGISTIC REGRESSION\n",
    "logreg = logreg.fit(X_train_nr, y_train_nr)\n",
    "y_pred = logreg.predict(test_set_des)\n",
    "print('accuracy %s' % accuracy_score(y_pred, test.label))\n",
    "print(classification_report(test.label, y_pred,target_names=my_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.4891222805701425\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "Non-violation       0.86      0.46      0.60      1101\n",
      "    Violation       0.20      0.64      0.30       232\n",
      "\n",
      "    micro avg       0.49      0.49      0.49      1333\n",
      "    macro avg       0.53      0.55      0.45      1333\n",
      " weighted avg       0.74      0.49      0.55      1333\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\defaultuser0.LAPTOP-6F0LJR1V\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#SUPPORT VECTOR MACHINE\n",
    "sgd.fit(X_train_nr, y_train_nr) #Use Description\n",
    "y_pred = sgd.predict(test_set_des)\n",
    "\n",
    "print('accuracy %s' % accuracy_score(y_pred, test.label))\n",
    "print(classification_report(test.label, y_pred,target_names=my_tags))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
